---
title: "Resumen 1 Experimentos"
author: "Daniel Sibaja Salazar"
output:
  html_document:
    toc: yes
    toc_float: yes
    toc-title: "índice"
    css: "tema1.css"
  pdf_document:
    toc: yes
---

# Introducción al tema

## Diseño de un experimento

-   El experimentador hace cambio deliberados en las variables de entrada de un proceso o sistema. Con el fin de identificar las razones de los cambios que pueden observarse en la variable respuesta.

-   También el experimentador está interesado en el efecto de algún proceso o intervención, llamado tratamiento sobre la respuesta de los objetos u unidades experimentales.

-   Cuando se pueden controlar los factores se pueden llegar a conclusiones de causa-efecto, el cambio de tratamiento es causante del cambio en la respuesta.

-   Cuando no se pueden controlar los factores se puede llegar a conclusiones de correlación.

### Ejemplos

**Situación en la que el cambio de las condiciones sea la causa del cambio en la salida:** Un experimento donde se estudia cómo diferentes niveles de luz afectan el crecimiento de las plantas. Al aumentar la cantidad de luz para un grupo de plantas mientras otro grupo permanece bajo condiciones normales, se observa que las plantas con más luz crecen significativamente más rápido. En este caso, el cambio en la cantidad de luz es la causa del cambio en el crecimiento de las plantas.

**Situación en la que no haya certeza de que las condiciones del factor sean la causa del cambio en la salida:** Imagina un experimento donde se estudia el efecto de la música en el rendimiento académico de los estudiantes. Un grupo de estudiantes escucha música mientras realiza una prueba, mientras que otro grupo realiza la misma prueba en silencio. Los resultados muestran que el grupo que escuchó música obtuvo mejores resultados. Sin embargo, no podemos estar seguros de que la música sea la causa directa de esta mejora, ya que otros factores como el estado de ánimo de los estudiantes o la motivación podrían haber influido en los resultados. En esta situación, aunque la salida (rendimiento académico) está asociada con las condiciones del factor (escuchar música), no hay certeza de que estas últimas sean la causa del cambio en la salida.

## Conceptos básicos

**Variable respuesta:** Variable que se estudia en un experimento y que se busca verificar si cambia al modificar las condiciones controlables.

**Tratamiento:** Cada una de las condiciones controlables que se modifican en un experimento.

**Factor:** Variable que se controla en un experimento y que puede tener diferentes niveles.

**Nivel de un factor:** Cada una de las posibilidades que se estudian de un factor.

**Efecto del tratamiento:** Diferencia entre el promedio de la variable respuesta en un tratamiento específico y el promedio general de la variable respuesta. Si el tratamiento no tiene efecto sobre la respuesta el efecto es 0

**Efecto positivo del tratamiento:** El promedio de la variable respuesta en un tratamiento específico es mayor que el promedio general.

**Efecto negativo del tratamiento:** El promedio de la variable respuesta en un tratamiento específico es menor que el promedio general.

**Promedio general:** Promedio de la variable respuesta considerando todos los datos de todos los tratamientos.

# Factores en experimentos

Es la varible una estudiar pero no siempre tengo control total de la misma. Pueden ser de diseño o no de diseño.

Los no de diseño y los medibles no controlables disminuyen la variabilidad.

Se pueden:

-   Fijar: Ya no es una varible en sí. Todos los elementos son iguales.

-   Controlar: dependdiendo del objetivo del estudio. Como los factores de diseño

-   Libre: Puede quedar como factor de ruido.

    -   Si no las puedo medir pueden meter variabilidad.

## Elección de os niveles de un factor y rangos.

-   Factores con pocos niveles son preferibles.
-   Las UE deben de ser lo más parecidas posibles.
    -   Si hay diferencias en las unidades es mejor otras variables medibles no de diseño para menor variabilidad
-   Si hay un nivel de control se refiere a que no e hace nada o se da el tratamiento clásico

# Pruebas de hipótesis.

## H0 o hipóteis nula.

$$
\mu_1=\mu_2=\mu_3=\mu_4
$$

Todos los promedios de los tratamientos son iguales

$$
\tau_1=\tau_2=\tau_3=\tau_4=0
$$

Los efectos de los tratamientos son todos iguales a 0.

## H1 o hipótesis alternativa.

Al menos un par de tratamientos producen medias diferentes.

El factor tiene un efecto sobre la media global.

# Errores

## Tipo I

Cuando se rechaza una hippótesis siendo verdaderaa

## Tipo II

Cuando no se rechaza siendo falsa

**Nota:** No conviene comparar de dos en dos las medias porque disparo el error tipo I

# Error experimental

Las diferencias entre unidades que están bajo un mimo tratamiento se atribuye o bien a un *error experimental aleatorio* o a *factores de ruido*

El mismo es esperado incluso tomando en cuenta todos los factores que influyen en la respuesta

# El modelo

Para la media condicional:

$$
\mu_j=\mu+\tau_j
$$

Para un observación

$$
y_{ij}=\mu+\tau_j+\epsilon_i
$$

En este caso entonces:

-   El efecto de un tratamiento es lo que diferencia a la media del tratamiento de la media general

-   El error es lo que diferencia a la oservación de la media del tratamiento.

## Supuestos del modelo

Casi los mismos de regresión

-   La distribución condicional es normal. En un tratamiento específico.

-   Igualdad de tratamientos.

-   Independencia

-   Homocedasticidad

Entonces $y_{ij}$ debería seguir un distriución normal con media $\mu_j$ y varianza $\sigma^2$

Y $\epsilon_{ij}$ es normal con media 0 y varianza $\sigma^2$

La vaarinza no tiene subindice por la homocedasticidad.

# Parametrizaciones de los modelos

Vamos a meter variables auxiliares.

# Suma nula

En este caso los coeficientes son 1 para el tratamiento de interés, 0 para los demás y -1 para el último.

$$
E[Y|trat_j]=\mu_j=\mu+\sum^{k-1}_{j=1}\tau_jC_j
$$ Entonces i quiero tengo interés en el segundo tratamiento tengo que

(1,0,1,0) es el vector, tomando en cuenta el intercepto

# Tratamiento de referencia

Tengo que

$$
\mu_j=\mu_1+\sum^{k-1}_{j=2}\delta_jD_j
$$ con

$$
\delta_j=\mu_j-\mu_1
$$ Tomo un 1 para el tratamiento de referencia como el intercepto y para las demás un 1 si es el de interés o un 0 si no

Por ejemplo:

-   si me interesa el tratamiento 2 tengo que (1,1,0,0)

-   Si me interesa el tratamiento 1 tengo que (1,0,0,0)

# Análisis de varianza

¿Cómo hacemos para para comprobar las hipótesis cuando queremos comparar más de dos promedios?

Con un *ANDEVA* que es una técnica estadística que nos permite justamente eso.

En el caso más sencillo hay dos fuentes de varianción

-   **Entre** tratamientos: Cuadrado Medio de tratanmientos CMTrat
-   **Dentro** de los tratamientos: Cuadrado medio residual CMRes

## Suma de cuadrados total

$$SCTot=\sum^n_{i=1}(y_i-\bar y )^2$$ O bien así=

$$
SCTot=SCTrat+SCRes
$$

## CMTrat:

Mide la varianción que hay entre todos los promedios de los diferentes tratamientos.

$$
CMTrat= \frac{\sum r_j(\bar y_j-\bar y)}{k-1}=\frac{SCTrat}{k-1}
$$

## CMRes

Una buena estimación de la variabilidad dentro de los tratamientos es el promedio ponderado de las varianzas de cada tratamiento.

Sirve para resumir todas la varianzas de los tratamientos en una sola medida

**Nota:** Si el experimento no es balaceado hay que ponderar.

$$
CMRes=\frac{\sum(r_j-1)s^2_j}{n-k} = \frac{SCRes}{n-k}
$$

Si es balanceado se puede resumir a:

$$
\frac{\sum^k_{j=1}s^2_j}{k}
$$

# Valores esperados de los cuadrados medios

$$
E(CMRes)=\sigma^2
$$

$$
E(CMtrat)=\sigma^2+\frac{\sum^k_{j=1}r_j\tau^2_j}{k-1}
$$

Bajo la hipótesis nula cierta:

Quiere decir que los $\tau_j=0$ por lo tanto $E(CMtrat)=\sigma^2$

Entocnes para probar la hipótesis de que los efectos de los tratamientos son nulos hay que probar que

$$
E(CMRes)=E(CMTrat)
$$

# Distribución de las sumas de cuadrados

-   Sean n observaciones $y_i$ independientes provenientes de una misma disstribución normal con media $\mu$ y varianza $\sigma^2$

-   La variable $\sum^n_{i=1}\frac{(y_i-y)^2}{\sigma^2}$ sigue una distribución Chi cuadrado con n-1 grados de libertad

-   Por lo tanto: $SCTrat/\sigma^2$ tiene dist chi con k-1 grados de libertad y $SCRes/\sigma^2$ sigue una distribución chi con n-k grados de libertad

## Teorema de Cochran

Los términos $SC_i/\sigma^2$ son variables chi cuadrado independientes.

## Distribución del cociente

El estadístico F se calcula de la siguiente forma:

$$
F=\frac{CMTrat}{CMRes}
$$

Hay que recordar que si se tienen dos variables chi cuadrado independientes, el cociente de ellas entre sus respectivos grados de libertad sigue una distribución F

Tomando esto en cuenta entonces:

-   Si la hipótesis nula es verdadera es de esperarse que tanto el CMTrat como el CMRes tengan magnitudes similares.
    -   Incluso CMTrat\<CMRes
-   Si H0 es falsa se espera que CMTrat\>CMRes
-   Por lo tanto se puede usar el cociente de distribución F para hacer la prueba de hipótesis ya que si H0 es verdadera este valor debe de estar cerca de 1

# Caso de un factor con dos niveles

Cuando se analiza un factor con solo dos niveles se puede usar la distribución $t$, se obtiene un resultado equivalente al del ANDEVA

Tengo que:

$$
H0: \mu_1=\mu_2
$$ 

$$
H0: \tau_1=0
$$

Entonces la hipótesis alternativa es de dos colas

$$
H1: \mu_1 \neq \mu_2
$$

Se debe de obtenr la estimación del efecto $\hat \tau_1$ y su desviación estándar y con ellos se calcula el estadístico t.

$$
t=\frac{\hat \tau_1}{ee_{\hat \tau_1}}
$$

Y con la ayuda de la distribución t se obtiene la probabilidad asociada. Se utiliza una distribución t con n-k grados de libertad. Esta probabilidad debe de ser igual a la que se obtiene con la distribución F.

# Constrastes y comparaciones múltiples.

Recordemos la hipótesis del modelo



$$\mu_1=\mu_2=\mu_3=\mu_4$$

O sea que todos los promedios (o efectos) son iguales, si rechazamos la hipótesis nula, hay suficiente evidencia estadística para saber que por lo menos hay un par de medias distinto *¿Pero cuál?*

Tenemos varios casos según el interés que tengamos.

## Caso 1: comparar todos los pares de medias.

Supongamos que tenemos un experimento con un facotr y 4 niveles. Entonces tenemos las siguientes hipótesis

1.  $\mu_1=\mu_2$
2.  $\mu_1=\mu_3$
3.  $\mu_1=\mu_4$
4.  $\mu_2=\mu_3$
5.  $\mu_2=\mu_4$
6.  $\mu_3=\mu_4$

En este caso tenemos dos opciones:

* Tukey, prueba que sirve específicamente para comparar todos los pares de promedios
* Comparaciones múltiples con corrección para no inflar el error tipo I

En este caso no es necesario verificar indepencia debido a que se sabe que si se hace de esta forma las hipótesis no son independientes.

## Caso 2: Solo comparar un promedio con los demás. 

### Caso 2.a 

En este caso tenemos hipótesis de este estilo.

1. $\mu_1=\frac{\mu_2+\mu_3+\mu_4}{3}$ 

2.  $\mu_2=\frac{\mu_3+\mu_4}{2}$

Cada hipótesis significa que el promedio de los demás es igual a $\mu_1$ o $\mu_2$

En este caso solo se pueden usar contrastes, y hay que verificar independencia para ver si se hace corrección o no


### Caso 3.a 

Tenemos hipótesis de este estilo:

1. $\mu_1=\mu_2$
2. $\mu_1=\mu_3$
3. $\mu_1=\mu_4$

O sea, solo comparamos un promedio con cada uno de los demás, en este caso se debe de hacer una prueba de Dunnet

# Contrastes

Un contraste es una combinación lineal L de los promedios de los diferentes tratamientos con la condición de que la suma de los pesos sea 0. 

$$
L=\sum_{j=1}^k c_j\mu_j
$$
donde 

$$
\sum_{j=1}^k c_j=0
$$


- Hay dos formas de estimarlos
  - Con los promedios
  - Con los coeficientes
- Siempre es necesario definir si hace falta corrección o no. 

## Estimación con los promedios. 

Imaginemos que tenemos un experimento de un factor y 4 niveles, entonces según lo visto tenemos que 

$$L=c_1\mu_1+c_2\mu_2+c_3\mu_3+c_4\mu_4$$

Tenemos las hipótesis siguientes:

* $H0: \mu_1=\mu_2$
* $H0: \mu_2=\mu_3$

En este caso nos conviene escribirlos de la siguiente forma. 

* $H0: \mu_1-\mu_2=0$
* $H0: \mu_2-\mu_3=0$

Dichos comparaciones es más fácil convertirlas en vectores 

$$L_1=1\mu_1+-1\mu_2+0\mu_3+0\mu_4$$

Entonces tenemos un vector de C así (1,-1,0,0)

$$L_2=0\mu_1+1\mu_2+-1\mu_3+0\mu_4$$

Entonces tenemos un vector de C así (0,1,-1,0)


### Verificar independencia

Para verificar independencia de las hipótesis es necesario verificar la *ortogonalidad* de los vectores. 

Para eso se calcula el producto punto de los vectores 

```{r}
v1=c(1,-1,0,0)
v2=c(0,1,-1,0)

v1%*%v2

crossprod(v1,v2)
```

Si el produco punto es 

* =0 enconces hay independencia y no se hace corrección de Bonferroni

* <>0 enconces no hay independencia y se hace corrección de Bonferroni (como en ese caso)


Veamos ahora el caso de de un factor con 3 niveles e hipótesis distintas. 

* $H0: \mu_1=\frac{1}{2}(\mu_2+\mu_3)$

* $H0: \mu_2=\mu_3$


Asumiendo que $L=c_1\mu_1+c_2\mu_2+c_3\mu_3$

Tenemos entonces que:

* $L_1 = \mu_1-\frac{1}{2}(\mu_2+\mu_3)$
* $L_2 = \mu_2-\mu_3$


Los vectores serían los siguientes.

* v1=(1,-1/2,1/2)
* v2=(0,1,-1)

Podemos analizar la independencia 

```{r}
v1=c(1,-1/2,1/2)
v2=c(0,1,-1)

crossprod(v1,v2)
```

## Estimación de los contrastes 

Hasta ahora estábamos trabajando con las medias poblacionales, sin embargo, lo común es tener acceso únicamente a las medias muestrales, por lo que es necesario estimarlo 

$$
\hat L=\sum^k_{j=1}c_j\bar y_j 
$$

Cálculo del cual ocupamos su varianza y error estándar 

La varianza de un contraste es la siguiente;

$$
\hat V [\hat L] = \sum^k_{j=1}c^2_j\hat V[\bar y _j]=\sum^k_{j=1}c^2_j\frac{CMRes}{r_j}=CMRes\sum^k_{j=1}\frac{c_j^2}{r_j}
$$
Esta es la varianza pero 
¿Cuál es el error estándar? ¿Para qué vamos a hacer inteevalos de todas formas?

### Demotración 





## Estimación con los coeficientes


Sea $\beta$ el vector de coeficientes del modelo y $h_k$ el vector de coeficientes del contraste $L_k$ entonces: (PREGUNTAR)

$$\hat L_k = h_k\hat \beta$$

Y la varianza 

$$
\hat V[\hat L_k]=h_k^T\hat V[\hat \beta]h_k
$$


```{r echo=FALSE}
knitr::include_graphics("C:/Users/danie/OneDrive/Cosas/Escritorio/Carrera/Experimentos/Fotos resumenes/1.png")
```

# Comparaciones múltiples

* Para determinar cuales contrastes son diferentes de 0 se debe de evitar hacer pruebas simples de forma separada porque se aumenta la probabilidad de error tipo I 

* Cuando se tiene un modelo de efectos fijos, hay métodos estadísticos para hacer todas las comparaciones y a la vez matener el ala en un nivel deseado

* **SI H0 NO SE RECHAZA ESTE PASO CARECE DE SENTIDO**

## Comparaciones por partes de Tukey

* Cuando solo se quieren hacer contrastes para comparar los pares de medias, el método de Tukey produce intervalos más angostos que los de Bonferroni o Scheffé

* Para construir un intervalo de confianza para diferencia de dos medias se tiene lo siguiente

$$
ee = \sqrt{CMRes(\frac{1}{r_j}+\frac{1}{r_j})}
$$

Y los intervalos 

$$
Intervalos(1-\alpha)=(\bar y_i-\bar y_j) +- q_{\alpha,k,n-k}*ee
$$

También se puede usar el CMRes en el error estándar.

Esto tiene ventajas y desventajas:

- Al usar el CMRes se usa información de todas las varianzas, ya que el CMRes es una ponderación de todas las varianzas 

- Su uso presupone Hoommocedasticidad, en caso de que las varianzas no sean iguales, es mejor usar las varianzas de cada grupo por separado

- Si se tiene el mismo tamaño de muestra iguales a "r" en todos los casos el EE se reduce 

$$
EE=\sqrt{\frac{2CMRes}{r}}
$$


- R asume tamaños de muestra iguales y la fórmula de "q" ya incluye el 2 del EE, por lo que si se calcula el EE estándar con la fórmula correcta (la anterior) el valor de "q" que se obtiene en  R debe dividirse por $\sqrt 2$ para que el resultado sea correcto.

# Comparaciones por partes de Dunnett

* Este método se usa solo cuando se requiere hacer comparaciones de un tratamiento contra todos los demás. 

- Estas comparaciones deben plantearse desde el diseño 

- Supone que es un experimento balanceado.